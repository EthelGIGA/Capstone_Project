{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e68916",
   "metadata": {},
   "source": [
    "# PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84602ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f534ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data in notebook\n",
    "data = pd.read_csv(\"C:/Users/Ethel Enam Nyamador/Desktop/WACCBIP/Drug Discovery/Project/SCARA5 Target.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61895532",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a588d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select essential features\n",
    "essential_features = data[[\"Molecule ChEMBL ID\", \"Smiles\", \"Standard Value\"]]\n",
    "essential_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab06a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop nul values (NaN) in essential features\n",
    "essential_features = essential_features.dropna()\n",
    "essential_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group compunds into activity class\n",
    "bioactivity_class = []\n",
    "for i in essential_features['Standard Value']:\n",
    "  if float(i) >= 1000:\n",
    "    bioactivity_class.append(\"inactive\")\n",
    "  else:\n",
    "    bioactivity_class.append(\"active\")\n",
    "\n",
    "bioactivity_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21925a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Append a new column to the data\n",
    "essential_features[\"Bioactivity\"] = bioactivity_class\n",
    "essential_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68dc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bar chart for bioactivity class\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "sns.countplot(x='Bioactivity', data=essential_features, edgecolor='blue')\n",
    "\n",
    "plt.title('Bar chart of Bioactivity class', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Bioactivity class', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=13, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical fetaures to numeric\n",
    "encoded_class = []\n",
    "for i in essential_features.Bioactivity:\n",
    "  if i == \"active\":\n",
    "    encoded_class.append(1)\n",
    "  else:\n",
    "    encoded_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ebb8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "essential_features[\"Numerical class\"] = encoded_class\n",
    "essential_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = essential_features[[\"Molecule ChEMBL ID\", \"Smiles\"]]\n",
    "dd.to_csv(\"cleaned_data.csv\", index=False)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import rdkit\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Smiles to Morgan fingerprints\n",
    "def morgan_fpts(data):\n",
    "    Morgan_fpts = []\n",
    "    for i in data:\n",
    "        mol = Chem.MolFromSmiles(i) \n",
    "        fpts =  AllChem.GetMorganFingerprintAsBitVect(mol,2,2048)\n",
    "        mfpts = np.array(fpts)\n",
    "        Morgan_fpts.append(mfpts)   \n",
    "    return np.array(Morgan_fpts)\n",
    "\n",
    "Morgan_fpts = morgan_fpts(dd[\"Smiles\"])\n",
    "Morgan_fingerprints = pd.DataFrame(Morgan_fpts,columns=['Col_{}'.format(i) for i in range(Morgan_fpts.shape[1])])\n",
    "Morgan_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert fingerprints to csv file\n",
    "Morgan_fingerprints.to_csv(\"fingerprints.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88274933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open fingerprints csv file\n",
    "fingerprints = pd.read_csv(\"fingerprints.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a645a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge fingerprints with bioactivity classes to form a single dataset\n",
    "fingerprints[\"Bioactivity\"] = essential_features[\"Numerical class\"]\n",
    "whole_data = fingerprints\n",
    "whole_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert whole data to csv file\n",
    "whole_data.to_csv(\"whole_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all nul values\n",
    "whole_data = whole_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into target feature and independent features\n",
    "X = whole_data.drop(\"Bioactivity\", axis = 1)\n",
    "y = whole_data[\"Bioactivity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f679066",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training using LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_classification(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "\n",
    "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training using StackingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a random binary classification dataset (replace with your actual data)\n",
    "X, y = make_classification(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "lr_model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Define the base estimators with Logistic Regression and RandomForest\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('lr', LogisticRegression()) \n",
    "]\n",
    "\n",
    "# Create a Stacking Classifier that combines Logistic Regression and RandomForest\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Fit the stacking classifier on the training data\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for the entire pipeline\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of Stacking Classifier:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbe6ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15551348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "#Import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)  # Replace y_true and y_pred with your actual and predicted labels\n",
    "\n",
    "# Create a ConfusionMatrixDisplay object\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Display the confusion matrix plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Stacking Classifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78593571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8330a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceffed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ab15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf20da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43574e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
